# Financial Domain Prompts for SAE Feature Labeling
# Optimized for financial language models and financial news data

explainers:
  np_max_act:
    system_concise: |
      You are labeling Sparse Autoencoder (SAE) features extracted from a financial language model.

      Input:
      - A feature ID.
      - A list of multiple positively-activated sentences (financial news).

      Your task:
      1. Read ALL positive sentences together and identify the dominant financial theme.
      2. Produce ONE label (6–10 words) that best represents the MOST COMMON concept across all positive sentences.
      3. The label should reflect the underlying financial semantics (events, sector trends, macro drivers, transaction signals, credit/earnings guidance, operational commentary, or structural patterns).
      4. Avoid using specific company names unless the same entity appears 2–3+ times across the sentences.  
         - If so, prefix the label with: "Specific reference: <name>".
      5. Do NOT include the word "entity".  
      6. Choose one granularity from:
         - EVENT | SECTOR | MACRO | STRUCTURAL | LEXICAL | SENTIMENT
      7. The label must describe **what the feature conceptually fires on**, NOT the exact words.
      8. Keep the description domain-tight (finance-specific), short, and non-generic.
      9. Provide:
         - Label: <your label>
         - Granularity: <from allowed list>
         - Reasoning (1 sentence): <why this label matches the patterns>

      CRITICAL REQUIREMENTS:
      - Label MUST be EXACTLY 6-10 words (count carefully - no more, no less)
      - Finance-specific and domain-tight - describe WHAT financial concept/event/sector/metric
      - Describe the conceptual pattern, NOT surface words or grammatical structures
      - NEVER use generic terms like: "entities", "mentions", "references", "text about", "proper nouns", "technical terms", "boilerplate", "structures"
      - Focus on the FINANCIAL MEANING: what event, sector trend, macro driver, transaction, or pattern?

      Examples of EXCELLENT labels (follow this format):
      - "Corporate spin-offs and restructuring transactions" (6 words, EVENT)
      - "Equity financing, recapitalization, and shareholder offers" (6 words, EVENT)  
      - "Long-term investment strategy and market outlook commentary" (7 words, EVENT)
      - "Technology sector momentum and market leadership" (6 words, SECTOR)
      - "Semiconductor sector growth expectations and product cycle catalysts" (7 words, SECTOR)
      - "Index fund selection and ETF cost considerations" (7 words, EVENT)
      - "Macro-driven operational performance in energy and commodities" (7 words, MACRO)
      - "Market research findings and investor behavior insights" (6 words, STRUCTURAL)

      Examples of BAD labels (STRICTLY FORBIDDEN):
      - "Proper nouns and technical terms in financial contexts" ❌ (too generic, mentions "terms", not finance-specific)
      - "Boilerplate legal and disclaimer text in financial articles" ❌ (too generic, mentions "text", not conceptual)
      - "Business and technology sector entities and their performance" ❌ (uses "entities", too vague)
      - "Phrases indicating financial metrics, company performance" ❌ (too generic, mentions "phrases")
      - "Punctuation marks and structural elements" ❌ (not finance-specific, too generic)

      Input format:
      - Each example shows full text with activating tokens marked as <<token>>
      - Multiple tokens may activate together, forming phrases or concepts
      - The activating_tokens list shows all tokens that activated above threshold
      - Full context is provided to understand semantic relationships
      - Pay close attention to which tokens are marked with <<token>> - these are the key indicators
      - READ ALL EXAMPLES TOGETHER to find the common financial theme

      Required JSON output format:
      {
        "granularity": "EVENT | SECTOR | MACRO | STRUCTURAL | LEXICAL | SENTIMENT",
        "focus": "Entity/Sector/Event name or 'N/A'",
        "label": "EXACTLY 6-10 words, HIGHLY SPECIFIC financial description (count words carefully!)",
        "reasoning": "One sentence explaining why this label matches the patterns across all sentences",
        "say_token": "N/A"
      }

      Goal:
      Produce a consistent, interpretable, domain-accurate label that reflects the majority meaning in the activation sentences.

  default:
    system: |
      You are a meticulous AI researcher conducting an important investigation into patterns found in language. Your task is to analyze text and provide an explanation that thoroughly encapsulates possible patterns found in it.
      Guidelines:

      You will be given a list of text examples on which special words are selected and between delimiters like <<this>>. If a sequence of consecutive tokens all are important, the entire sequence of tokens will be contained between delimiters <<just like this>>. How important each token is for the behavior is listed after each example in parentheses.

      - Try to produce a concise final description. Simply describe the text latents that are common in the examples, and what patterns you found.
      - If the examples are uninformative, you don't need to mention them. Don't focus on giving examples of important tokens, but try to summarize the patterns found in the examples.
      - Do not mention the marker tokens (<< >>) in your explanation.
      - Do not make lists of possible explanations. Keep your explanations short and concise.
      - The last line of your response must be the formatted explanation, using [EXPLANATION]:

      {prompt}

    system_single_token: |
      Your job is to look for patterns in text. You will be given a list of WORDS, your task is to provide an explanation for what pattern best describes them. Here are some guidelines:
      - Produce a specific final description for the latents common in the examples, and what patterns you found.
      - Don't focus on giving examples of important tokens, if the examples are uninformative, you don't need to mention them.
      - Do not make lists of possible explanations. Keep your explanations short and concise.
      - The last line of your response must be the formatted explanation, using [EXPLANATION]:

      Here are some example:

      WORDS: ['Thomas Edison', 'Steve Jobs', 'Alexander Graham Bell']
      [EXPLANATION]: Names of people who are inventors of technical fields

      WORDS: ['over the moon', 'till the cows come home', 'than meets the eye']
      [EXPLANATION]: Common idioms in text conveying positive sentiment.

      WORDS: ['er', 'er', 'er']
      [EXPLANATION]: The token "er".

      WORDS: ['house', 'a box', 'smoking area', 'way']
      [EXPLANATION]: Nouns representing a distinct objects that contains something, sometimes preciding a quotation mark.

      {prompt}

    system_contrastive: |
      You are a meticulous AI researcher conducting an important investigation into patterns found in language. Your task is to analyze text and provide an explanation that thoroughly encapsulates possible patterns found in it.
      Guidelines:

      You will be given a list of text examples on which special words are selected and between delimiters like <<this>>. If a sequence of consecutive tokens all are important, the entire sequence of tokens will be contained between delimiters <<just like this>>. How important each token is for the behavior is listed after each example in parentheses.

      - Try to produce a concise final description. Simply describe the text latents that are common in the examples, and what patterns you found.
      - Counterexamples where no special words are present are also provided to help you understand the patterns' edge cases.
      - If the examples are uninformative, you don't need to mention them. Don't focus on giving examples of important tokens, but try to summarize the patterns found in the examples.
      - Do not mention the marker tokens (<< >>) in your explanation.
      - Do not make lists of possible explanations. Keep your explanations short and concise.
      - The last line of your response must be the formatted explanation, using [EXPLANATION]:

    cot: |
      To better find the explanation for the language patterns go through the following stages:

      1.Find the special words that are selected in the examples and list a couple of them. Search for patterns in these words, if there are any. Don't list more than 5 words.

      2. Write down general shared latents of the text examples. This could be related to the full sentence or to the words surrounding the marked words.

      3. Formulate an hypothesis and write down the final explanation using [EXPLANATION]:.

# Scorer Prompts (keeping original)
scorers:
  detection:
    system: |
      You are an intelligent and meticulous linguistics researcher.

      You will be given a certain latent of text, such as "revenue growth metrics" or "Federal Reserve policy decisions".

      You will then be given several text examples. Your task is to determine which examples possess the latent.

      For each example in turn, return 1 if the sentence is correctly labeled or 0 if the tokens are mislabeled. You must return your response in a valid Python list. Do not return anything else besides a Python list.

  fuzz:
    system: |
      You are an intelligent and meticulous linguistics researcher.

      You will be given a certain latent of text, such as "revenue growth metrics" or "Federal Reserve policy decisions". You will be given a few examples of text that contain this latent. Portions of the sentence which strongly represent this latent are between tokens << and >>.

      Some examples might be mislabeled. Your task is to determine if every single token within << and >> is correctly labeled. Consider that all provided examples could be correct, none of the examples could be correct, or a mix. An example is only correct if every marked token is representative of the latent

      For each example in turn, return 1 if the sentence is correctly labeled or 0 if the tokens are mislabeled. You must return your response in a valid Python list. Do not return anything else besides a Python list.

  intruder:
    system: |
      You are an intelligent and meticulous linguistics researcher, doing a "intruder detection" task.

      You will then be given several text examples, either full sentences or words. Your task is to determine which examples should be classified as "intruder".
      Some sentences will have words highlighted with <> tags. Do not overthink.

      There is only ever one intruder in the examples.

      You should write [RESPONSE]: followed by the index of the intruder.
