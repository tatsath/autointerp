#!/usr/bin/env python3
"""
Create a summary document analyzing explanation vs activating words for multiple features.
"""

import json
import argparse
from pathlib import Path
from analyze_explanation_vs_tokens import (
    load_cached_latents,
    show_top_tokens_for_feature,
    load_explanation,
    find_hookpoint_in_latents,
    get_model_from_config,
)
from transformers import AutoTokenizer


def create_summary_report(
    results_dir: Path,
    hookpoint: str,
    feature_ids: list[int],
    base_model: str,
    activations,
    locations,
    tokens,
    tokenizer,
    output_file: Path,
):
    """Create a summary report for multiple features."""
    
    with open(output_file, "w") as f:
        f.write("=" * 80 + "\n")
        f.write("FEATURE EXPLANATION vs ACTIVATING WORDS ANALYSIS\n")
        f.write("Understanding the Discrepancy Between LLM Explanations and Token Frequencies\n")
        f.write("=" * 80 + "\n\n")
        
        f.write("EXECUTIVE SUMMARY\n")
        f.write("-" * 80 + "\n")
        f.write("""
This document explains why feature explanations (generated by LLM explainers) may differ
from the top activating words (from statistical token analysis). The key insight is:

1. EXPLANATIONS = Semantic interpretation of full context
2. TOP WORDS = Statistical frequency of individual tokens

They complement each other but measure different things.
\n""")
        
        f.write("=" * 80 + "\n")
        f.write("HOW EXPLANATIONS ARE GENERATED\n")
        f.write("=" * 80 + "\n\n")
        f.write("""
The LLM explainer (Qwen/Qwen2.5-72B-Instruct) receives:

1. TOP 15-25 STRONGEST ACTIVATING EXAMPLES
   - Full text sequences (32 tokens of context)
   - Examples centered on the activation point
   - Each example shows which tokens activated (marked with <<token>>)

2. THE PROMPT ASKS:
   "Look at the parts of the document the neuron activates for and summarize
   in a single sentence what the neuron is activating on. Try not to be overly
   specific. Your explanation should cover most or all activating words."

3. THE LLM DOES:
   - Semantic abstraction across examples
   - Pattern recognition in context
   - Generalization to a concept
   - NOT just word counting

\n""")
        
        f.write("=" * 80 + "\n")
        f.write("HOW TOP WORDS ARE CALCULATED\n")
        f.write("=" * 80 + "\n\n")
        f.write("""
The token analysis:

1. SAMPLES TOP 50,000 STRONGEST ACTIVATIONS
   - Individual token positions
   - No surrounding context
   - Just the token ID and activation value

2. COUNTS FREQUENCY
   - How many times each token appears
   - Maximum activation per token
   - Average activation per token

3. RANKS BY ACTIVATION STRENGTH
   - Sorted by max_activation, then count
   - Shows which tokens fire most strongly
   - BUT loses semantic context

\n""")
        
        f.write("=" * 80 + "\n")
        f.write("FEATURE-BY-FEATURE ANALYSIS\n")
        f.write("=" * 80 + "\n\n")
        
        for feat_id in feature_ids:
            f.write(f"\n{'=' * 80}\n")
            f.write(f"Feature {feat_id}\n")
            f.write(f"{'=' * 80}\n\n")
            
            # Get explanation
            explanation = load_explanation(results_dir, hookpoint, feat_id)
            f.write(f"Explanation: {explanation}\n\n")
            
            # Get top words
            top_words = show_top_tokens_for_feature(
                feat_id, activations, locations, tokens, tokenizer,
                top_k=15, sample_size=50000
            )
            
            f.write("Top 15 Activating Words:\n")
            f.write("-" * 80 + "\n")
            for i, (text, count, tid, max_act, avg_act) in enumerate(top_words[:15], 1):
                f.write(f"{i:2d}. {repr(text):30s}  max={max_act:6.2f}  count={count:5d}\n")
            
            f.write("\nAnalysis:\n")
            f.write("-" * 80 + "\n")
            
            # Simple analysis
            if explanation and top_words:
                f.write(f"The explanation '{explanation}' captures a semantic pattern that may not\n")
                f.write(f"be obvious from individual words. The top words show frequent tokens,\n")
                f.write(f"but the explanation shows what those tokens MEAN IN CONTEXT.\n")
                f.write(f"\nFor example, words like '{top_words[0][0] if top_words else 'N/A'}' may appear\n")
                f.write(f"frequently, but when seen in full context across multiple examples, the\n")
                f.write(f"LLM recognizes a pattern related to '{explanation}'.\n")
            
            f.write("\n\n")
        
        f.write("=" * 80 + "\n")
        f.write("CONCLUSION\n")
        f.write("=" * 80 + "\n\n")
        f.write("""
KEY TAKEAWAYS:

1. EXPLANATIONS ARE SEMANTIC, NOT STATISTICAL
   - They interpret meaning across examples
   - They capture patterns in context
   - They generalize to concepts

2. TOP WORDS ARE STATISTICAL, NOT SEMANTIC
   - They show frequency and strength
   - They lose context
   - They show WHAT fires, not WHAT IT MEANS

3. BOTH ARE VALID AND COMPLEMENTARY
   - Top words: "What tokens activate?"
   - Explanation: "What semantic pattern do they represent?"

4. WHY THEY DIFFER
   - Common words (like "Industry", "Third", "Should") may appear frequently
   - But in context, they form patterns (like "Special dividend declarations")
   - The LLM explainer sees the forest, token analysis sees the trees

5. WHEN TO TRUST WHICH
   - Trust explanations for: Understanding what the feature captures semantically
   - Trust top words for: Understanding which specific tokens trigger it
   - Use both for: Complete picture of feature behavior

\n""")
        
        f.write("=" * 80 + "\n")
        f.write("METHODOLOGY\n")
        f.write("=" * 80 + "\n\n")
        f.write("""
This analysis was generated by:
- Loading cached activations from safetensors files
- Sampling top 50,000 activations per feature
- Extracting top 15-30 meaningful words (filtered for letters)
- Comparing with LLM-generated explanations from autointerp_full

The explanation model saw:
- Top 15-25 strongest activating examples
- Full 32-token context windows
- Examples centered on activation points
- Semantic similarity-based negative examples

\n""")


def main():
    parser = argparse.ArgumentParser(description="Create explanation analysis summary")
    parser.add_argument("results_dir", type=str, help="Results directory")
    parser.add_argument("--features-from-list", type=str, help="Feature list file")
    parser.add_argument("--max-features", type=int, default=10, help="Max features to analyze")
    parser.add_argument("--output", type=str, default=None, help="Output file")
    
    args = parser.parse_args()
    
    results_dir = Path(args.results_dir).resolve()
    latents_dir = results_dir / "latents"
    
    # Auto-detect
    hookpoint = find_hookpoint_in_latents(latents_dir)
    base_model = get_model_from_config(latents_dir, hookpoint)
    
    # Load feature list
    if args.features_from_list:
        with open(args.features_from_list) as f:
            feature_ids = [int(x) for x in f.read().strip().split()]
        feature_ids = feature_ids[:args.max_features]
    else:
        # Use features from explanations
        explanations_dir = results_dir / "explanations"
        pattern = f"{hookpoint}_latent"
        feature_ids = []
        for file in explanations_dir.glob(f"{pattern}*.txt"):
            feat_str = file.name.replace(f"{pattern}", "").replace(".txt", "")
            try:
                feature_ids.append(int(feat_str))
            except:
                pass
        feature_ids = sorted(feature_ids)[:args.max_features]
    
    print(f"Analyzing {len(feature_ids)} features: {feature_ids[:5]}...")
    
    # Load data
    tokenizer = AutoTokenizer.from_pretrained(base_model)
    activations, tokens, locations, config = load_cached_latents(results_dir, hookpoint)
    
    # Set output
    if args.output is None:
        output_file = results_dir / "feature_analysis" / "explanation_vs_words_analysis.txt"
    else:
        output_file = Path(args.output)
    output_file.parent.mkdir(exist_ok=True, parents=True)
    
    # Create report
    create_summary_report(
        results_dir, hookpoint, feature_ids, base_model,
        activations, locations, tokens, tokenizer, output_file
    )
    
    print(f"\nâœ“ Summary report saved to: {output_file}")


if __name__ == "__main__":
    main()

