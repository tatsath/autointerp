{
    "cache_cfg": {
        "dataset_repo": "wikitext",
        "dataset_split": "train[:1%]",
        "dataset_name": "wikitext-103-raw-v1",
        "dataset_column": "text",
        "batch_size": 32,
        "cache_ctx_len": 256,
        "n_tokens": 10000,
        "n_splits": 5
    },
    "constructor_cfg": {
        "faiss_embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
        "faiss_embedding_cache_dir": ".embedding_cache",
        "faiss_embedding_cache_enabled": true,
        "example_ctx_len": 32,
        "min_examples": 1,
        "n_non_activating": 2,
        "center_examples": true,
        "non_activating_source": "FAISS",
        "neighbours_type": "co-occurrence"
    },
    "sampler_cfg": {
        "n_examples_train": 40,
        "n_examples_test": 50,
        "n_quantiles": 10,
        "train_type": "quantiles",
        "test_type": "quantiles",
        "ratio_top": 0.2
    },
    "model": "meta-llama/Llama-2-7b-hf",
    "sparse_model": "/home/nvidia/Documents/Hariom/saetrain/trained_models/llama2_7b_hf_layers4 10 16 22 28_k32_latents400_wikitext103_torchrun",
    "hookpoints": [
        "layers.22"
    ],
    "explainer_model": "Qwen/Qwen2.5-7B-Instruct",
    "explainer_model_max_len": 2048,
    "explainer_provider": "offline",
    "explainer": "default",
    "scorers": [
        "detection"
    ],
    "name": "multi_layer_full_layer22",
    "max_latents": null,
    "feature_num": [
        220,
        101,
        353,
        239,
        387,
        303,
        396,
        184,
        83,
        276
    ],
    "filter_bos": true,
    "log_probs": false,
    "load_in_8bit": false,
    "hf_token": null,
    "pipeline_num_proc": 120,
    "num_gpus": 4,
    "seed": 22,
    "verbose": true,
    "num_examples_per_scorer_prompt": 1,
    "overwrite": []
}